---
layout: post
title: 周报（2015）
comments: false
---

2015/6/28日起，每周一计划，每日一检查。希冀自己养成有计划，勤反思的习惯。

2015年的周报记录在这里，就不更新了。

<!--more-->

### Index ###
<hr/>
- [作息时间](#times)
- [Deadlines](#deadlines)
- Weeks
	- [2015/6/28 - 2015/7/4](#week_1)
	- [2015/7/5 - 2015/7/11](#week_2)
	- [2015/7/12 - 2015/7/18](#week_3)
	- [2015/7/19 - 2015/7/25](#week_4)
	- [2015/7/26 - 2015/8/1](#week_5)
	- [2015/8/2 - 2015/8/8](#week_6)
	- [2015/8/9 - 2015/8/15](#week_7)
	- [2015/8/16 - 2015/8/22](#week_8)
	- [2015/8/23 - 2015/8/29](#week_9)
	- [2015/8/30 - 2015/9/6](#week_10)
	- [2015/9/7 - 2015/9/13](#week_11)
	- [2015/9/14 - 2015/9/20](#week_12)
	- [2015/9/21 - 2015/9/27](#week_13)
	- [2015/9/28 - 2015/10/4](#week_14)
	- [2015/10/5 - 2015/10/11](#week_15)
	- [2015/10/12 - 2015/10/18](#week_16)
	- [2015/10/19 - 2015/10/25](#week_17)
	- [2015/10/26 - 2015/11/1](#week_18)
	- [2015/11/2 - 2015/11/8](#week_19)
	- [2015/11/9 - 2015/11/15](#week_20)
	- [2015/11/16 - 2015/11/22](#week_21)
	- [2015/11/23 - 2015/11/29](#week_22)
	- [2015/11/30 - 2015/12/6](#week_23)
	- [2015/12/7 - 2015/12/13](#week_24)
	- [2015/12/14 - 2016/1/10](#week_25_28)
	- [2016/1/11 - 2016/1/17](#week_29)
	- [2016/1/18 - 2016/1/24](#week_30)


<a id="times"></a>

### 作息时间 ### 
<hr/>
在校工作日正常作息时间（计划中，据实调整）：

- 7：00 起床
- 7：30 早饭
- 7：50 口语
- 8：20 实验室，安排一天的任务
- 8：30 开始上午的工作
- 11：30 午饭
- 12：10 午休
- 13：00 开始下午的工作
- 17：20 晚饭
- 18：00 宿舍，运动
- 19：30 开始晚上的工作
- 23：30 总结一天的工作
- 24：00 休息

初步的时间安排如此，需要一段时间来调整，期间可以统计下专注工作的有效时间。

<a id="deadlines"></a>

### Deadlines###
<hr/>
- ~~CVPR16 2015/11/6~~
- ECCV16 2016/3/14

<a id="week_1"></a>

### 2015/6/28 - 2015/7/4 ###
<hr/>

**To-do List**:

- 解析Caffe源码之Layer, Net, Solver
- 实现CVPR15 paper: "Learning Descriptors for Object Recognition and 3D Pose Estimation"
- 准备报告CVPR15 paper: "Deep Neural Networks Are Easily Fooled: High Confidence Predictions for Unrecognizable Images"

<a id="week_2"></a>

### 2015/7/5 - 2015/7/11 ###
<hr/>

**上周总结**

按计划有节奏的工作真的很难，

1. 不能严格执行作息时间，对自己放松要求。自律自制。
2. 效率低下，专注工作时很容易被打断。工作时停掉社交软件。

上周任务完成情况：

1. caffe源码之Layer部分的阅读完成了[data layer部分](http://imbinwang.github.io/blog/inside-caffe-code-layer/)，剩下vision layer, neuron layer, loss layer, common layer待完成。
2. 实现CVPR15 paper的计划未开始，原始数据已准备（模型，RGBD图像序列和ground truth），等第1项工作（caffe源码解析）完成后开始。
3. 已准备好报告CVPR15 paper: "Going Deeper with Convolutions"，另一份报告"Deep Neural Networks Are Easily Fooled: High Confidence Predictions for Unrecognizable Images"正在准备中，这周可以完成两次论文报告。

**To-do List**:

- ~~完成解析Caffe源码之Layer的剩余部分vision layer, neuron layer, loss layer, common layer~~
- 实现CVPR15 paper: "Learning Descriptors for Object Recognition and 3D Pose Estimation"，任务分解：
	1. 数据准备，包括重新实现空间采样算法、3-tuple数据组织并存入levelDB数据库
	2. 待数据准备完成后，安排下一步

7月6号组会上钟老师建议**先动手做实验**，故Caffe解析系列先暂停。

<a id="week_3"></a>

### 2015/7/12 - 2015/7/18 ###
<hr/>

**上周总结**

计划完成的工作无实质性进展，一周不知道做了什么就过去了。这周只做一件事，只做一件事，只做一件事。

**To-do List**:

- 空间视点采样，渲染模型数据，2-tuple和3-tuple存入数据库

<a id="week_4"></a>

### 2015/7/19 - 2015/7/25 ###
<hr/>

**上周总结**

IRC暑期学校准备。

**To-do List**:

- 青岛暑期学校一周

<a id="week_5"></a>

### 2015/7/26 - 2015/8/1 ###
<hr/>

**上周总结**

一周的暑期学校，第一次见识青岛。

休假，回家两周。

<a id="week_6"></a>

### 2015/8/2 - 2015/8/8 ###
<hr/>

**上周总结**

在家放空。

<a id="week_7"></a>

### 2015/8/9 - 2015/8/15 ###
<hr/>

**上周总结**

假期结束了，放空好了，回来得抓紧了。


**To-do List**:

- 想想在写吧

<a id="week_8"></a>

### 2015/8/16 - 2015/8/22 ###
<hr/>

**上周总结**

上周一下午回的学院，得知中心两篇论文被SIGA接收，高兴又悲伤，国锋师兄的project再次遗憾，同时自己的课题一直没有实质进展。马上就进入第4年的学习，感觉到了时间紧迫和毕业压力。心里有些焦虑，但还是不能急,不能乱。

上周完成了新的视点采样算法；将caffe官方github代码库中的更新应用到了自己本地的caffe框架；注意到目标检测邻域大牛[Ross Girshick](http://www.cs.berkeley.edu/~rbg/)的两篇新作[Fast-RCNN](http://arxiv.org/abs/1504.08083)和[Faster-RCNN](http://arxiv.org/abs/1506.01497),他的算法(从DPM到RCNN再到Fast-RCNN)一直都是object detection的state of the art，自己的课题也从他的新作中获得了一些想法；测试了基于caffe的[Fast-RCNN代码](https://github.com/rbgirshick/fast-rcnn)，效果不错。

**To-do List**:

- DeepFitting课题也摸索了大半年了，自己对整个问题重新思考了一遍，周一和秦老师讨论后再来更新to-do list

<a id="week_9"></a>

### 2015/8/23 - 2015/8/29 ###
<hr/>

**上周总结**

上周和CVPR15"Learning Descriptors"的作者Paul进行了简单的交流，得知当前有学生正在基于caffe和opencv实现他的工作[cnn_3dobj](https://github.com/Wangyida/)，对cnn_3dobj进行了少量改动后开始了对Paul工作的测试。

**To-do List**:

- 重现Paul论文中的实验室，验证其工作的有效性
- 服务器安装完成后，在其上测试修改后的caffe框架，熟悉整个caffe在Ubuntu下的工作流程

<a id="week_10"></a>

### 2015/8/30 - 2015/9/6 ###
<hr/>

**上周总结**

Paul的CVPR15工作的开源实现代码在实际运行过程中有bug，拖延症的我并没有fix the bug。IRC的DL服务器安装完成，在服务器上跑了caffe的测试，跑Paul的工作没有完成后，就拖着了。想借鉴Yangyan他们的工作流程：python blender渲染 + caffe，没有完全耐得住心学习他们的代码。

像只鸵鸟一样，以为把头埋在沙子里就没有问题了吗？直面现实，有问题就想办法解决。

**To-do List**:

- Fix Paul开源代码中的bug
- 学会python blender渲染
- 学习服务器上用脚本比较自动化地完成模型训练及可视化分析

**工作日志**

- 8/31，Paul开源代码[cnn_3dobj](https://github.com/Wangyida/)中gpu代码triple_loss_layer.cu bug fixed。gpu显存访问权限问题，`caffe_gpu_dot`输出结果必须到内存，显存赋值函数是`caffe_gpu_set`(`caffe_set`用于内存赋值)。
- 9/1，Paul工作在LINEMOD数据集上的训练完成，中间结果的可视化完成。

<a id="week_11"></a>

### 2015/9/7 - 2015/9/13 ###
<hr/>

**上周总结**

Paul工作在简单数据上的测试完成。

**To-do List**:

- 按Paul论文实验思路，尽可能复现其结果
- 完成LINEMOD dataset的blender python渲染脚本

<a id="week_12"></a>

### 2015/9/14 - 2015/9/20 ###
<hr/>

**上周总结**

上周主要在做数据渲染工作，Blender渲染LINEMOD数据集的脚本基本完成，当前正在渲染。Paul的工作还没来得及完全复现。

**To-do List**:

- 完成Paul工作中CNN模型的训练

**工作日志**

- 9/16，LINEMOD数据集的ground truth渲染完成，bounding box计算完成
- 9/18，LINEMOD数据集的training 数据集渲染完成，bounding box计算完成

<a id="week_13"></a>

### 2015/9/21 - 2015/9/27 ###
<hr/>

**上周总结**

LINEMOD的ground truth和training数据集渲染完成。

**To-do List**:

- 完成Paul工作中CNN模型的训练
- 训练模型结果可视化
- 测试集上的近邻查找

<a id="week_14"></a>

### 2015/9/28 - 2015/10/4 ###
<hr/>

**上周总结**

Paul工作中CNN模型的训练完毕，结果可视化完成，测试集上的测试集上的近邻查找完成。

**To-do List**:

- 用当前数据集和相关标注去Fine-tune Fast RCNN，完成对LINEMOD中物体的2d detection(涉及到开源库[Fast RCNN](https://github.com/rbgirshick/fast-rcnn),[selective search](https://github.com/sergeyk/selective_search_ijcv_with_python))

<a id="week_15"></a>

### 2015/10/5 - 2015/10/11 ###
<hr/>

**上周总结**

没有实质进展。

**To-do List**:

- 熟悉使用[Fast RCNN](https://github.com/rbgirshick/fast-rcnn)和[selective search](https://github.com/sergeyk/selective_search_ijcv_with_python)
- 验证Paul工作提取的特征，用在检测框架下的可行性

<a id="week_16"></a>

### 2015/10/12 - 2015/10/18 ###
<hr/>

**上周总结**

code reading and testing。Paul工作提取的特征，用在检测框架下的效果不佳，可能的原因是背景杂乱和尺度不一致。

**To-do List**:

- 完成[Fast RCNN](https://github.com/rbgirshick/fast-rcnn)在LINEMOD数据集上的检测测试

<a id="week_17"></a>

### 2015/10/19 - 2015/10/25 ###
<hr/>

**上周总结**

手动调整了测试图像尺度，将训练好的Pual工作中网络结构调整为Full Convolutional Net, 采用了kdtree fast knn重新测试了检测效果，速度有了较大提升，检测效果并未见提升； FRCNN流程跑通，已完成对LINEMOD数据集中一类物体的检测。

**To-do List**:

- 使用LINDMOD全体类别的数据训练能检测LINEMOD 15类物体的网络， 并测试检测效果
- 用于姿态估计的网络PaulNet和用于2D检测的FRCNN分别跑通，分析结果，思考如何借鉴已有的两个网络设计新的网络结构完成多任务（recognition, 2D detection and 3d pose estimation）

<a id="week_18"></a>

### 2015/10/26 - 2015/11/1 ###
<hr/>

**上周总结**

LINEMOD 15类物体的检测测试完成。检测准确率还行，但是很多bounding box没有完整的框住物体，不知道这会对后续的姿态估计产生什么影响。

**To-do List**:

- 基于Fast-RCNN, 完成识别检测三维定位多任务网络的代码。

<a id="week_19"></a>

### 2015/11/2 - 2015/11/8 ###
<hr/>

**上周总结**

没有实质进展，将之前的代码重新整理了。修改了LINEMOD渲染代码的灯光设置，增加了数据生成的噪声代码，网络输入数据格式由LevelDB变更成了LMDB。

**To-do List**:

- 基于Fast-RCNN和Faster-RCNN, 完成识别检测三维定位多任务网络的代码。

<a id="week_20"></a>

### 2015/11/9 - 2015/11/15 ###
<hr/>

**上周总结**

基于Fast-RCNN，完成了识别检测三维定位（当前仅预测4DOF四元数表达的旋转参数）多任务网络的代码，网络还未开始训练，等待实验结果。

**To-do List**:

- 如何预测另外3DOF的位置信息？Fast-RCNN中提出的ROIPooling具有旋转不变性（去掉了bounding box中物体的尺度信息），导致了深度信息z丢失，需考虑怎么预测物体的位置信息。
- 测试Faster-RCNN，尝试修改之。论文指出Faster-RCNN比Fast-RCNN更快速，功能一样并且检测准确率稍有提升。

<a id="week_21"></a>

### 2015/11/16 - 2015/11/22 ###
<hr/>

**上周总结**

上周的同时2d检测和3d姿态估计的网络训练完成。单从2d检测的结果看来，测试结果比只有只有2d检测的单任务网络的检测结果要糟糕。导致这种情况的原因可能有，

1. 3d姿态估计的损失导致的权值更新干扰了2d检测损失引起的权值更新，导致当前学习的网络权值不是最有利于2d检测的；
2. 网络迭代次数不够多，导致网络权值并非位于一个较优的状态。

**To-do List**:

- 分析失败原因，调整训练参数，重新训练网络

<a id="week_22"></a>

### 2015/11/23 - 2015/11/29 ###
<hr/>

**上周总结**

上周更正两处代码错误，重新训练了新的网络参数。现在的测试结果比较合理，网络可以同时估计2d bounding boxes和3d rotation pose(四元数表示)，其中2d bounding boxes预测准确性高，3d rotation pose预测的结果略差于2d bounding boxes的预测。完成了结果的可视化，用估计的姿态重新将模型渲染到图像。

**To-do List**:

- 四元数表示的3d rotation parameters自身约束（旋转轴为单位向量）怎么处理？
- 3d translation parameters(X,Y,Z) 怎么预测？ XY可能与bounding box有关，Z影响物体在图像中的大小（尺度）。当前使用的网络并非尺度不变，Z值对网络的预测结果应该会有很大影响。
- 当前训练集使用了真实数据，换作渲染数据时结果会怎么样？

<a id="week_23"></a>

### 2015/11/30 - 2015/12/6 ###
<hr/>

**上周总结**

之前的训练集和测试集全部来着真实数据，为验证渲染数据训练网络的可行性，正在试验使用渲染数据训练网络，真实数据作测试的效果。

**To-do List**:

- 加旋转参数自身约束，旋转轴长度为单位1
- 预测位移参数的Z值，根据bounding box的位置，预测位移参数的XY

<a id="week_24"></a>

### 2015/12/7 - 2015/12/13 ###
<hr/>

**上周总结**

使用渲染数据作训练集训练网络，真实数据作测试集的结果非常糟糕。分析可能的原因的是我在渲染图像的背景上加了分形噪声模拟背景，导致测试的时候识别结果总是偏向背景。现使用纯属背景的数据重新训练网络。

论文根据自己的想法，粗略的写完了Introduction。

**To-do List**:

- 如果渲染数据的结果满意，下一步就是预测位移参数的Z值，根据bounding box的位置，预测位移参数的XY

<a id="week_25_28"></a>

### 2015/12/14 - 2016/1/10 ###
<hr/>

**上4周总结**

很惭愧，自己没能坚持写周报，16年的第一次周报。过去的4周，测试用渲染合成数据训练Fast RCNN，检测真实场景图片中的物体，效果均不佳。

渲染合成方式包括，对前景：

1. 无噪声的渲染前景，每个视点渲染1张前景图像；

对背景：

1. perlin noise 分形噪声做背景，每个视点合成1张背景图像；
2. 灰色背景，每个视点合成1张背景图像；
3. 黑色背景，每个视点合成1张背景图像；

测试的实验结果表格这里没放。

实验后的基本结论有：

1. 噪声背景和纯色背景不工作，这两种类型的背景与真实场景背景差异不可忽略，且背景相对单调容易和前景耦合；
2. 无噪声的渲染前景与真实场景下拍摄的前景差异不可忽略（光照不一致），由于当前的卷积神经网络并不能得到光照不变性特征，应另设法减小两者差异对实验结果的影响；

正在进行中的测试是按照秦老师上次讨论时的思路：

1. 对前景，渲染每个视点时，使用了20种不同方差的随机高斯噪声augment前景；
2. 对背景，渲染每个视点时，从另外一个公开的自然场景数据集中随机选择20幅场景图作背景；

总之，现在每个视点的图像有20幅，数据总量是之前的20倍，各自增加前背景的随机性。初步测试结果表明，这样构建的数据集有效，检测结果较前面的测试有提高。待网络彻底训练完成，分析最后的结果。

**To-do List**:

- 待大数据集的测试结果。

<a id="week_29"></a>

### 2016/1/11 - 2016/1/17 ###
<hr/>

**上周总结**

上周完成：

1. 使用大数据集的测试，2D bounding box检测和3D pose估计都能进行，但是检测准确度和姿态估计的精度不会太高（主观判断，当前还没有写评估代码）；
2. 生成了1类200幅背景的图像集，为评价背景多少对网络训练的影响；
3. 将整个流程放到Faster RCNN上(还未完全完成)，之前是基于Fast RCNN。Fast RCNN流程中预处理提取候选bounding boxes的时间太长，特别是在图像集的量增大后，使用Faster RCNN能加快测试;

**To-do List**:

- 实验结果的评估代码
- 整个框架改到Faster RCNN

<a id="week_30"></a>

### 2016/1/18 - 2016/1/24 ###
<hr/>

**上周总结**

上周完成：

1. 整个流程使用Faster RCNN框架的代码完成；
2. 2d检测和3d姿态估计的结果评估代码完成；

**To-do List**:

